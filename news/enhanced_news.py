#!/usr/bin/env python3
"""
Ð Ð°ÑÑˆÐ¸Ñ€ÐµÐ½Ð½Ñ‹Ð¹ Ð½Ð¾Ð²Ð¾ÑÑ‚Ð½Ð¾Ð¹ Ð¼Ð¾Ð´ÑƒÐ»ÑŒ Ð´Ð»Ñ Ð°Ð½Ð°Ð»Ð¸Ð·Ð° ÐºÑ€Ð¸Ð¿Ñ‚Ð¾Ð²Ð°Ð»ÑŽÑ‚
- Telegram ÐºÐ°Ð½Ð°Ð»Ñ‹
- TradingView
- Investing.com
- Ð¡ÐµÐ½Ñ‚Ð¸Ð¼ÐµÐ½Ñ‚-Ð°Ð½Ð°Ð»Ð¸Ð· (VADER + BERT)
- ÐšÐ»Ð°ÑÑÐ¸Ñ„Ð¸ÐºÐ°Ñ†Ð¸Ñ Ð½Ð¾Ð²Ð¾ÑÑ‚ÐµÐ¹
"""

import asyncio
import re
import time
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass
import requests
from bs4 import BeautifulSoup
import pandas as pd
import numpy as np
from textblob import TextBlob
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
import torch
from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification
import logging

# ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ° Ð»Ð¾Ð³Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class NewsItem:
    """Ð Ð°ÑÑˆÐ¸Ñ€ÐµÐ½Ð½Ð°Ñ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð° Ð½Ð¾Ð²Ð¾ÑÑ‚Ð¸"""
    id: str
    source: str
    channel: str
    title: str
    text: str
    url: str
    date_utc: datetime
    sentiment_score: float
    sentiment_label: str
    category: str
    impact_score: float
    crypto_mentions: List[str]
    price_impact: Optional[float] = None

@dataclass
class NewsSource:
    """ÐšÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ñ Ð¸ÑÑ‚Ð¾Ñ‡Ð½Ð¸ÐºÐ° Ð½Ð¾Ð²Ð¾ÑÑ‚ÐµÐ¹"""
    name: str
    type: str  # telegram, tradingview, investing
    url: str
    api_key: Optional[str] = None
    channels: List[str] = None

class SentimentAnalyzer:
    """ÐŸÑ€Ð¾Ð´Ð²Ð¸Ð½ÑƒÑ‚Ñ‹Ð¹ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°Ñ‚Ð¾Ñ€ ÑÐµÐ½Ñ‚Ð¸Ð¼ÐµÐ½Ñ‚Ð°"""
    
    def __init__(self):
        self.vader = SentimentIntensityAnalyzer()
        self.bert_model = None
        self.bert_tokenizer = None
        self._load_bert()
    
    def _load_bert(self):
        """Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÐ¼ BERT Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð´Ð»Ñ Ð±Ð¾Ð»ÐµÐµ Ñ‚Ð¾Ñ‡Ð½Ð¾Ð³Ð¾ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°"""
        try:
            # Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ Ñ„Ð¸Ð½Ð°Ð½ÑÐ¾Ð²ÑƒÑŽ Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð´Ð»Ñ Ð»ÑƒÑ‡ÑˆÐµÐ³Ð¾ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°
            model_name = "ProsusAI/finbert"
            self.bert_tokenizer = AutoTokenizer.from_pretrained(model_name)
            self.bert_model = AutoModelForSequenceClassification.from_pretrained(model_name)
            logger.info("BERT Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð° ÑƒÑÐ¿ÐµÑˆÐ½Ð¾")
        except Exception as e:
            logger.warning(f"BERT Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð½Ðµ Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð°: {e}")
            self.bert_model = None
    
    def analyze_sentiment(self, text: str) -> Dict[str, Any]:
        """ÐÐ½Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐµÐ¼ ÑÐµÐ½Ñ‚Ð¸Ð¼ÐµÐ½Ñ‚ Ñ‚ÐµÐºÑÑ‚Ð°"""
        # VADER Ð°Ð½Ð°Ð»Ð¸Ð·
        vader_scores = self.vader.polarity_scores(text)
        
        # BERT Ð°Ð½Ð°Ð»Ð¸Ð· (ÐµÑÐ»Ð¸ Ð´Ð¾ÑÑ‚ÑƒÐ¿ÐµÐ½)
        bert_score = None
        if self.bert_model and len(text) > 10:
            try:
                inputs = self.bert_tokenizer(text, return_tensors="pt", truncation=True, max_length=512)
                with torch.no_grad():
                    outputs = self.bert_model(**inputs)
                    probs = torch.softmax(outputs.logits, dim=1)
                    bert_score = float(probs[0][1])  # Positive probability
            except Exception as e:
                logger.warning(f"BERT Ð°Ð½Ð°Ð»Ð¸Ð· Ð½Ðµ ÑƒÐ´Ð°Ð»ÑÑ: {e}")
        
        # ÐšÐ¾Ð¼Ð±Ð¸Ð½Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ð¹ Ð°Ð½Ð°Ð»Ð¸Ð·
        if bert_score is not None:
            # Ð’Ð·Ð²ÐµÑˆÐµÐ½Ð½Ð¾Ðµ ÑÑ€ÐµÐ´Ð½ÐµÐµ VADER Ð¸ BERT
            combined_score = 0.4 * vader_scores['compound'] + 0.6 * (bert_score - 0.5) * 2
        else:
            combined_score = vader_scores['compound']
        
        # ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»ÑÐµÐ¼ Ð»ÐµÐ¹Ð±Ð»
        if combined_score >= 0.1:
            label = "POSITIVE"
        elif combined_score <= -0.1:
            label = "NEGATIVE"
        else:
            label = "NEUTRAL"
        
        return {
            "vader_compound": vader_scores['compound'],
            "vader_positive": vader_scores['pos'],
            "vader_negative": vader_scores['neg'],
            "vader_neutral": vader_scores['neu'],
            "bert_score": bert_score,
            "combined_score": combined_score,
            "label": label
        }

class NewsClassifier:
    """ÐšÐ»Ð°ÑÑÐ¸Ñ„Ð¸ÐºÐ°Ñ‚Ð¾Ñ€ Ð½Ð¾Ð²Ð¾ÑÑ‚ÐµÐ¹ Ð¿Ð¾ ÐºÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ð¸ÑÐ¼"""
    
    def __init__(self):
        self.categories = {
            "regulation": ["regulation", "sec", "cfdc", "government", "ban", "legal"],
            "adoption": ["adoption", "partnership", "enterprise", "institutional", "adoption"],
            "technology": ["upgrade", "fork", "protocol", "smart contract", "defi", "nft"],
            "market": ["bull", "bear", "rally", "crash", "volatility", "liquidity"],
            "mining": ["mining", "hashrate", "difficulty", "block reward"],
            "exchange": ["exchange", "listing", "delisting", "trading", "volume"]
        }
    
    def classify_news(self, text: str) -> str:
        """ÐšÐ»Ð°ÑÑÐ¸Ñ„Ð¸Ñ†Ð¸Ñ€ÑƒÐµÐ¼ Ð½Ð¾Ð²Ð¾ÑÑ‚ÑŒ Ð¿Ð¾ ÐºÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ð¸Ð¸"""
        text_lower = text.lower()
        scores = {}
        
        for category, keywords in self.categories.items():
            score = sum(1 for keyword in keywords if keyword in text_lower)
            scores[category] = score
        
        if not any(scores.values()):
            return "general"
        
        return max(scores, key=scores.get)

class CryptoMentionExtractor:
    """Ð˜Ð·Ð²Ð»ÐµÐºÐ°ÐµÐ¼ ÑƒÐ¿Ð¾Ð¼Ð¸Ð½Ð°Ð½Ð¸Ñ ÐºÑ€Ð¸Ð¿Ñ‚Ð¾Ð²Ð°Ð»ÑŽÑ‚"""
    
    def __init__(self):
        # ÐžÑÐ½Ð¾Ð²Ð½Ñ‹Ðµ ÐºÑ€Ð¸Ð¿Ñ‚Ð¾Ð²Ð°Ð»ÑŽÑ‚Ñ‹
        self.crypto_symbols = {
            "BTC": ["bitcoin", "btc"],
            "ETH": ["ethereum", "eth"],
            "BNB": ["binance coin", "bnb"],
            "ADA": ["cardano", "ada"],
            "SOL": ["solana", "sol"],
            "DOT": ["polkadot", "dot"],
            "DOGE": ["dogecoin", "doge"],
            "MATIC": ["polygon", "matic"],
            "LTC": ["litecoin", "ltc"],
            "XRP": ["ripple", "xrp"]
        }
    
    def extract_mentions(self, text: str) -> List[str]:
        """Ð˜Ð·Ð²Ð»ÐµÐºÐ°ÐµÐ¼ ÑƒÐ¿Ð¾Ð¼Ð¸Ð½Ð°Ð½Ð¸Ñ ÐºÑ€Ð¸Ð¿Ñ‚Ð¾Ð²Ð°Ð»ÑŽÑ‚"""
        text_lower = text.lower()
        mentions = []
        
        for symbol, keywords in self.crypto_symbols.items():
            if any(keyword in text_lower for keyword in keywords):
                mentions.append(symbol)
        
        return mentions

class ImpactScorer:
    """ÐžÑ†ÐµÐ½ÐºÐ° Ð²Ð»Ð¸ÑÐ½Ð¸Ñ Ð½Ð¾Ð²Ð¾ÑÑ‚Ð¸ Ð½Ð° Ñ€Ñ‹Ð½Ð¾Ðº"""
    
    def __init__(self):
        self.impact_keywords = {
            "high": ["breaking", "urgent", "exclusive", "major", "significant"],
            "medium": ["announcement", "update", "partnership", "launch"],
            "low": ["rumor", "speculation", "analysis", "opinion"]
        }
    
    def calculate_impact(self, text: str, source: str, sentiment_score: float) -> float:
        """Ð Ð°ÑÑÑ‡Ð¸Ñ‚Ñ‹Ð²Ð°ÐµÐ¼ Ð¾Ñ†ÐµÐ½ÐºÑƒ Ð²Ð»Ð¸ÑÐ½Ð¸Ñ Ð½Ð¾Ð²Ð¾ÑÑ‚Ð¸"""
        text_lower = text.lower()
        
        # Ð‘Ð°Ð·Ð¾Ð²Ñ‹Ð¹ ÑÐºÐ¾Ñ€ Ð¿Ð¾ ÐºÐ»ÑŽÑ‡ÐµÐ²Ñ‹Ð¼ ÑÐ»Ð¾Ð²Ð°Ð¼
        base_score = 0.5
        for level, keywords in self.impact_keywords.items():
            if any(keyword in text_lower for keyword in keywords):
                if level == "high":
                    base_score = 0.9
                elif level == "medium":
                    base_score = 0.7
                elif level == "low":
                    base_score = 0.3
                break
        
        # ÐœÐ¾Ð´Ð¸Ñ„Ð¸ÐºÐ°Ñ‚Ð¾Ñ€ Ð¿Ð¾ Ð¸ÑÑ‚Ð¾Ñ‡Ð½Ð¸ÐºÑƒ
        source_modifier = 1.0
        if source == "tradingview":
            source_modifier = 0.8
        elif source == "investing":
            source_modifier = 0.9
        elif source == "telegram":
            source_modifier = 0.7
        
        # ÐœÐ¾Ð´Ð¸Ñ„Ð¸ÐºÐ°Ñ‚Ð¾Ñ€ Ð¿Ð¾ ÑÐµÐ½Ñ‚Ð¸Ð¼ÐµÐ½Ñ‚Ñƒ
        sentiment_modifier = 1.0 + abs(sentiment_score) * 0.3
        
        # Ð¤Ð¸Ð½Ð°Ð»ÑŒÐ½Ñ‹Ð¹ ÑÐºÐ¾Ñ€
        impact_score = base_score * source_modifier * sentiment_modifier
        return min(1.0, max(0.0, impact_score))

class TelegramNewsCollector:
    """Ð¡Ð±Ð¾Ñ€Ñ‰Ð¸Ðº Ð½Ð¾Ð²Ð¾ÑÑ‚ÐµÐ¹ Ð¸Ð· Telegram"""
    
    def __init__(self, api_id: str, api_hash: str, phone: str):
        self.api_id = api_id
        self.api_hash = api_hash
        self.phone = phone
        self.client = None
    
    async def connect(self):
        """ÐŸÐ¾Ð´ÐºÐ»ÑŽÑ‡Ð°ÐµÐ¼ÑÑ Ðº Telegram"""
        try:
            from telethon import TelegramClient
            self.client = TelegramClient('crypto_news_session', self.api_id, self.api_hash)
            await self.client.start(phone=self.phone)
            logger.info("Telegram ÐºÐ»Ð¸ÐµÐ½Ñ‚ Ð¿Ð¾Ð´ÐºÐ»ÑŽÑ‡ÐµÐ½")
            return True
        except Exception as e:
            logger.error(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ð¾Ð´ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ñ Ðº Telegram: {e}")
            return False
    
    async def collect_news(self, channels: List[str], limit: int = 100) -> List[NewsItem]:
        """Ð¡Ð¾Ð±Ð¸Ñ€Ð°ÐµÐ¼ Ð½Ð¾Ð²Ð¾ÑÑ‚Ð¸ Ð¸Ð· ÐºÐ°Ð½Ð°Ð»Ð¾Ð²"""
        if not self.client:
            return []
        
        news_items = []
        
        for channel in channels:
            try:
                entity = await self.client.get_entity(channel)
                messages = await self.client.get_messages(entity, limit=limit)
                
                for msg in messages:
                    if msg.text and len(msg.text) > 20:
                        news_item = NewsItem(
                            id=f"tg_{msg.id}",
                            source="telegram",
                            channel=channel,
                            title=msg.text[:100] + "..." if len(msg.text) > 100 else msg.text,
                            text=msg.text,
                            url="",
                            date_utc=msg.date,
                            sentiment_score=0.0,
                            sentiment_label="NEUTRAL",
                            category="general",
                            impact_score=0.5,
                            crypto_mentions=[]
                        )
                        news_items.append(news_item)
                
            except Exception as e:
                logger.error(f"ÐžÑˆÐ¸Ð±ÐºÐ° ÑÐ±Ð¾Ñ€Ð° Ð½Ð¾Ð²Ð¾ÑÑ‚ÐµÐ¹ Ð¸Ð· {channel}: {e}")
        
        return news_items

class TradingViewCollector:
    """Ð¡Ð±Ð¾Ñ€Ñ‰Ð¸Ðº Ð½Ð¾Ð²Ð¾ÑÑ‚ÐµÐ¹ Ð¸Ð· TradingView"""
    
    def __init__(self):
        self.base_url = "https://www.tradingview.com"
        self.headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
        }
    
    def collect_news(self, limit: int = 50) -> List[NewsItem]:
        """Ð¡Ð¾Ð±Ð¸Ñ€Ð°ÐµÐ¼ Ð½Ð¾Ð²Ð¾ÑÑ‚Ð¸ Ð¸Ð· TradingView"""
        try:
            # TradingView API endpoint Ð´Ð»Ñ Ð½Ð¾Ð²Ð¾ÑÑ‚ÐµÐ¹
            url = f"{self.base_url}/news/"
            response = requests.get(url, headers=self.headers, timeout=10)
            
            if response.status_code != 200:
                logger.warning(f"TradingView Ð²ÐµÑ€Ð½ÑƒÐ» ÑÑ‚Ð°Ñ‚ÑƒÑ {response.status_code}")
                return []
            
            soup = BeautifulSoup(response.content, 'html.parser')
            news_items = []
            
            # ÐŸÐ°Ñ€ÑÐ¸Ð¼ Ð½Ð¾Ð²Ð¾ÑÑ‚Ð¸ (ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð° Ð¼Ð¾Ð¶ÐµÑ‚ Ð¼ÐµÐ½ÑÑ‚ÑŒÑÑ)
            news_elements = soup.find_all('div', class_='tv-news-item')
            
            for i, element in enumerate(news_elements[:limit]):
                try:
                    title_elem = element.find('a', class_='tv-news-item__title')
                    if not title_elem:
                        continue
                    
                    title = title_elem.get_text(strip=True)
                    url = self.base_url + title_elem.get('href', '')
                    
                    # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ð¿Ð¾Ð»Ð½Ñ‹Ð¹ Ñ‚ÐµÐºÑÑ‚ Ð½Ð¾Ð²Ð¾ÑÑ‚Ð¸
                    full_text = self._get_full_text(url)
                    
                    news_item = NewsItem(
                        id=f"tv_{i}",
                        source="tradingview",
                        channel="tradingview",
                        title=title,
                        text=full_text or title,
                        url=url,
                        date_utc=datetime.utcnow() - timedelta(hours=i),
                        sentiment_score=0.0,
                        sentiment_label="NEUTRAL",
                        category="general",
                        impact_score=0.5,
                        crypto_mentions=[]
                    )
                    news_items.append(news_item)
                    
                except Exception as e:
                    logger.error(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ð°Ñ€ÑÐ¸Ð½Ð³Ð° Ð½Ð¾Ð²Ð¾ÑÑ‚Ð¸ TradingView: {e}")
            
            return news_items
            
        except Exception as e:
            logger.error(f"ÐžÑˆÐ¸Ð±ÐºÐ° ÑÐ±Ð¾Ñ€Ð° Ð½Ð¾Ð²Ð¾ÑÑ‚ÐµÐ¹ TradingView: {e}")
            return []
    
    def _get_full_text(self, url: str) -> str:
        """ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ð¿Ð¾Ð»Ð½Ñ‹Ð¹ Ñ‚ÐµÐºÑÑ‚ Ð½Ð¾Ð²Ð¾ÑÑ‚Ð¸"""
        try:
            response = requests.get(url, headers=self.headers, timeout=10)
            if response.status_code == 200:
                soup = BeautifulSoup(response.content, 'html.parser')
                content = soup.find('div', class_='tv-news-item__content')
                if content:
                    return content.get_text(strip=True)
        except Exception as e:
            logger.warning(f"ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð¿Ð¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ Ð¿Ð¾Ð»Ð½Ñ‹Ð¹ Ñ‚ÐµÐºÑÑ‚: {e}")
        return ""

class InvestingCollector:
    """Ð¡Ð±Ð¾Ñ€Ñ‰Ð¸Ðº Ð½Ð¾Ð²Ð¾ÑÑ‚ÐµÐ¹ Ð¸Ð· Investing.com"""
    
    def __init__(self):
        self.base_url = "https://www.investing.com"
        self.headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
        }
    
    def collect_news(self, limit: int = 50) -> List[NewsItem]:
        """Ð¡Ð¾Ð±Ð¸Ñ€Ð°ÐµÐ¼ Ð½Ð¾Ð²Ð¾ÑÑ‚Ð¸ Ð¸Ð· Investing.com"""
        try:
            url = f"{self.base_url}/cryptocurrency-news/"
            response = requests.get(url, headers=self.headers, timeout=10)
            
            if response.status_code != 200:
                logger.warning(f"Investing.com Ð²ÐµÑ€Ð½ÑƒÐ» ÑÑ‚Ð°Ñ‚ÑƒÑ {response.status_code}")
                return []
            
            soup = BeautifulSoup(response.content, 'html.parser')
            news_items = []
            
            # ÐŸÐ°Ñ€ÑÐ¸Ð¼ Ð½Ð¾Ð²Ð¾ÑÑ‚Ð¸
            news_elements = soup.find_all('article', class_='js-article-item')
            
            for i, element in enumerate(news_elements[:limit]):
                try:
                    title_elem = element.find('a', class_='title')
                    if not title_elem:
                        continue
                    
                    title = title_elem.get_text(strip=True)
                    url = self.base_url + title_elem.get('href', '')
                    
                    # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ð¿Ð¾Ð»Ð½Ñ‹Ð¹ Ñ‚ÐµÐºÑÑ‚
                    full_text = self._get_full_text(url)
                    
                    news_item = NewsItem(
                        id=f"inv_{i}",
                        source="investing",
                        channel="investing",
                        title=title,
                        text=full_text or title,
                        url=url,
                        date_utc=datetime.utcnow() - timedelta(hours=i),
                        sentiment_score=0.0,
                        sentiment_label="NEUTRAL",
                        category="general",
                        impact_score=0.5,
                        crypto_mentions=[]
                    )
                    news_items.append(news_item)
                    
                except Exception as e:
                    logger.error(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ð°Ñ€ÑÐ¸Ð½Ð³Ð° Ð½Ð¾Ð²Ð¾ÑÑ‚Ð¸ Investing: {e}")
            
            return news_items
            
        except Exception as e:
            logger.error(f"ÐžÑˆÐ¸Ð±ÐºÐ° ÑÐ±Ð¾Ñ€Ð° Ð½Ð¾Ð²Ð¾ÑÑ‚ÐµÐ¹ Investing: {e}")
            return []
    
    def _get_full_text(self, url: str) -> str:
        """ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ð¿Ð¾Ð»Ð½Ñ‹Ð¹ Ñ‚ÐµÐºÑÑ‚ Ð½Ð¾Ð²Ð¾ÑÑ‚Ð¸"""
        try:
            response = requests.get(url, headers=self.headers, timeout=10)
            if response.status_code == 200:
                soup = BeautifulSoup(response.content, 'html.parser')
                content = soup.find('div', class_='WYSIWYG articlePage')
                if content:
                    return content.get_text(strip=True)
        except Exception as e:
            logger.warning(f"ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð¿Ð¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ Ð¿Ð¾Ð»Ð½Ñ‹Ð¹ Ñ‚ÐµÐºÑÑ‚: {e}")
        return ""

class EnhancedNewsManager:
    """Ð“Ð»Ð°Ð²Ð½Ñ‹Ð¹ Ð¼ÐµÐ½ÐµÐ´Ð¶ÐµÑ€ Ð½Ð¾Ð²Ð¾ÑÑ‚ÐµÐ¹"""
    
    def __init__(self, telegram_config: Optional[Dict] = None):
        self.sentiment_analyzer = SentimentAnalyzer()
        self.news_classifier = NewsClassifier()
        self.crypto_extractor = CryptoMentionExtractor()
        self.impact_scorer = ImpactScorer()
        
        self.telegram_collector = None
        if telegram_config:
            self.telegram_collector = TelegramNewsCollector(
                telegram_config.get('api_id'),
                telegram_config.get('api_hash'),
                telegram_config.get('phone')
            )
        
        self.tradingview_collector = TradingViewCollector()
        self.investing_collector = InvestingCollector()
    
    async def collect_all_news(self, telegram_channels: List[str] = None) -> List[NewsItem]:
        """Ð¡Ð¾Ð±Ð¸Ñ€Ð°ÐµÐ¼ Ð½Ð¾Ð²Ð¾ÑÑ‚Ð¸ Ð¸Ð· Ð²ÑÐµÑ… Ð¸ÑÑ‚Ð¾Ñ‡Ð½Ð¸ÐºÐ¾Ð²"""
        all_news = []
        
        # Telegram Ð½Ð¾Ð²Ð¾ÑÑ‚Ð¸
        if self.telegram_collector and telegram_channels:
            try:
                await self.telegram_collector.connect()
                tg_news = await self.telegram_collector.collect_news(telegram_channels)
                all_news.extend(tg_news)
                logger.info(f"Ð¡Ð¾Ð±Ñ€Ð°Ð½Ð¾ {len(tg_news)} Ð½Ð¾Ð²Ð¾ÑÑ‚ÐµÐ¹ Ð¸Ð· Telegram")
            except Exception as e:
                logger.error(f"ÐžÑˆÐ¸Ð±ÐºÐ° ÑÐ±Ð¾Ñ€Ð° Telegram Ð½Ð¾Ð²Ð¾ÑÑ‚ÐµÐ¹: {e}")
        
        # TradingView Ð½Ð¾Ð²Ð¾ÑÑ‚Ð¸
        try:
            tv_news = self.tradingview_collector.collect_news()
            all_news.extend(tv_news)
            logger.info(f"Ð¡Ð¾Ð±Ñ€Ð°Ð½Ð¾ {len(tv_news)} Ð½Ð¾Ð²Ð¾ÑÑ‚ÐµÐ¹ Ð¸Ð· TradingView")
        except Exception as e:
            logger.error(f"ÐžÑˆÐ¸Ð±ÐºÐ° ÑÐ±Ð¾Ñ€Ð° TradingView Ð½Ð¾Ð²Ð¾ÑÑ‚ÐµÐ¹: {e}")
        
        # Investing.com Ð½Ð¾Ð²Ð¾ÑÑ‚Ð¸
        try:
            inv_news = self.investing_collector.collect_news()
            all_news.extend(inv_news)
            logger.info(f"Ð¡Ð¾Ð±Ñ€Ð°Ð½Ð¾ {len(inv_news)} Ð½Ð¾Ð²Ð¾ÑÑ‚ÐµÐ¹ Ð¸Ð· Investing.com")
        except Exception as e:
            logger.error(f"ÐžÑˆÐ¸Ð±ÐºÐ° ÑÐ±Ð¾Ñ€Ð° Investing Ð½Ð¾Ð²Ð¾ÑÑ‚ÐµÐ¹: {e}")
        
        return all_news
    
    def analyze_news(self, news_items: List[NewsItem]) -> List[NewsItem]:
        """ÐÐ½Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐµÐ¼ Ð²ÑÐµ Ð½Ð¾Ð²Ð¾ÑÑ‚Ð¸"""
        analyzed_news = []
        
        for item in news_items:
            try:
                # ÐÐ½Ð°Ð»Ð¸Ð· ÑÐµÐ½Ñ‚Ð¸Ð¼ÐµÐ½Ñ‚Ð°
                sentiment_result = self.sentiment_analyzer.analyze_sentiment(item.text)
                item.sentiment_score = sentiment_result['combined_score']
                item.sentiment_label = sentiment_result['label']
                
                # ÐšÐ»Ð°ÑÑÐ¸Ñ„Ð¸ÐºÐ°Ñ†Ð¸Ñ
                item.category = self.news_classifier.classify_news(item.text)
                
                # Ð˜Ð·Ð²Ð»ÐµÑ‡ÐµÐ½Ð¸Ðµ ÑƒÐ¿Ð¾Ð¼Ð¸Ð½Ð°Ð½Ð¸Ð¹ ÐºÑ€Ð¸Ð¿Ñ‚Ð¾Ð²Ð°Ð»ÑŽÑ‚
                item.crypto_mentions = self.crypto_extractor.extract_mentions(item.text)
                
                # ÐžÑ†ÐµÐ½ÐºÐ° Ð²Ð»Ð¸ÑÐ½Ð¸Ñ
                item.impact_score = self.impact_scorer.calculate_impact(
                    item.text, item.source, item.sentiment_score
                )
                
                analyzed_news.append(item)
                
            except Exception as e:
                logger.error(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð°Ð½Ð°Ð»Ð¸Ð·Ð° Ð½Ð¾Ð²Ð¾ÑÑ‚Ð¸ {item.id}: {e}")
        
        return analyzed_news
    
    def get_market_sentiment(self, news_items: List[NewsItem]) -> Dict[str, Any]:
        """ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ð¾Ð±Ñ‰Ð¸Ð¹ ÑÐµÐ½Ñ‚Ð¸Ð¼ÐµÐ½Ñ‚ Ñ€Ñ‹Ð½ÐºÐ°"""
        if not news_items:
            return {"overall_sentiment": 0.0, "sentiment_label": "NEUTRAL"}
        
        # Ð’Ð·Ð²ÐµÑˆÐµÐ½Ð½Ñ‹Ð¹ ÑÐµÐ½Ñ‚Ð¸Ð¼ÐµÐ½Ñ‚ Ð¿Ð¾ Ð²Ð»Ð¸ÑÐ½Ð¸ÑŽ Ð½Ð¾Ð²Ð¾ÑÑ‚ÐµÐ¹
        weighted_sentiment = sum(
            item.sentiment_score * item.impact_score for item in news_items
        ) / sum(item.impact_score for item in news_items)
        
        # ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»ÑÐµÐ¼ Ð»ÐµÐ¹Ð±Ð»
        if weighted_sentiment >= 0.1:
            sentiment_label = "BULLISH"
        elif weighted_sentiment <= -0.1:
            sentiment_label = "BEARISH"
        else:
            sentiment_label = "NEUTRAL"
        
        return {
            "overall_sentiment": weighted_sentiment,
            "sentiment_label": sentiment_label,
            "total_news": len(news_items),
            "positive_news": len([n for n in news_items if n.sentiment_label == "POSITIVE"]),
            "negative_news": len([n for n in news_items if n.sentiment_label == "NEGATIVE"]),
            "neutral_news": len([n for n in news_items if n.sentiment_label == "NEUTRAL"])
        }

# ÐŸÑ€Ð¸Ð¼ÐµÑ€ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ñ
async def main():
    """ÐŸÑ€Ð¸Ð¼ÐµÑ€ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ñ Ñ€Ð°ÑÑˆÐ¸Ñ€ÐµÐ½Ð½Ð¾Ð³Ð¾ Ð½Ð¾Ð²Ð¾ÑÑ‚Ð½Ð¾Ð³Ð¾ Ð¼Ð¾Ð´ÑƒÐ»Ñ"""
    
    # ÐšÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ñ Telegram (Ð·Ð°Ð¿Ð¾Ð»Ð½Ð¸Ñ‚Ðµ ÑÐ²Ð¾Ð¸Ð¼Ð¸ Ð´Ð°Ð½Ð½Ñ‹Ð¼Ð¸)
    telegram_config = {
        'api_id': 'YOUR_API_ID',
        'api_hash': 'YOUR_API_HASH',
        'phone': 'YOUR_PHONE'
    }
    
    # Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð¼ÐµÐ½ÐµÐ´Ð¶ÐµÑ€Ð°
    news_manager = EnhancedNewsManager(telegram_config)
    
    # ÐšÐ°Ð½Ð°Ð»Ñ‹ Telegram Ð´Ð»Ñ Ð¼Ð¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³Ð°
    telegram_channels = [
        "binanceupdates",
        "cryptocom",
        "coinbase",
        "kraken"
    ]
    
    # Ð¡Ð±Ð¾Ñ€ Ð½Ð¾Ð²Ð¾ÑÑ‚ÐµÐ¹
    print("ðŸ” Ð¡Ð¾Ð±Ð¸Ñ€Ð°ÐµÐ¼ Ð½Ð¾Ð²Ð¾ÑÑ‚Ð¸...")
    news_items = await news_manager.collect_all_news(telegram_channels)
    
    # ÐÐ½Ð°Ð»Ð¸Ð· Ð½Ð¾Ð²Ð¾ÑÑ‚ÐµÐ¹
    print("ðŸ“Š ÐÐ½Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐµÐ¼ Ð½Ð¾Ð²Ð¾ÑÑ‚Ð¸...")
    analyzed_news = news_manager.analyze_news(news_items)
    
    # ÐžÐ±Ñ‰Ð¸Ð¹ ÑÐµÐ½Ñ‚Ð¸Ð¼ÐµÐ½Ñ‚ Ñ€Ñ‹Ð½ÐºÐ°
    market_sentiment = news_manager.get_market_sentiment(analyzed_news)
    
    print(f"ðŸ“ˆ Ð¡ÐµÐ½Ñ‚Ð¸Ð¼ÐµÐ½Ñ‚ Ñ€Ñ‹Ð½ÐºÐ°: {market_sentiment['sentiment_label']}")
    print(f"ðŸ“Š ÐžÐ±Ñ‰Ð¸Ð¹ ÑÐºÐ¾Ñ€: {market_sentiment['overall_sentiment']:.3f}")
    print(f"ðŸ“° Ð’ÑÐµÐ³Ð¾ Ð½Ð¾Ð²Ð¾ÑÑ‚ÐµÐ¹: {market_sentiment['total_news']}")
    
    # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹
    news_df = pd.DataFrame([
        {
            'id': item.id,
            'source': item.source,
            'title': item.title,
            'sentiment_score': item.sentiment_score,
            'sentiment_label': item.sentiment_label,
            'category': item.category,
            'impact_score': item.impact_score,
            'crypto_mentions': ', '.join(item.crypto_mentions),
            'date': item.date_utc
        }
        for item in analyzed_news
    ])
    
    news_df.to_csv('AI/data/enhanced_news.csv', index=False)
    print(f"ðŸ’¾ ÐÐ¾Ð²Ð¾ÑÑ‚Ð¸ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ñ‹ Ð² AI/data/enhanced_news.csv")

if __name__ == "__main__":
    asyncio.run(main())
